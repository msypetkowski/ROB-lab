\documentclass[a4paper]{article}

\usepackage[a4paper,  margin=1.0in]{geometry}

\usepackage{graphicx}
\usepackage{float}
\usepackage{hyperref}

\usepackage{tikz}
% \usetikzlibrary{graphdrawing}
% \usegdlibrary{force}

\usepackage{tikz}
\usetikzlibrary{quotes}
\usetikzlibrary{shapes}
\usetikzlibrary{graphdrawing}
\usetikzlibrary{graphs}
\usegdlibrary{trees}
\usegdlibrary{circular}
\usegdlibrary{force} % <-- ADD LIBRARY !!!
\definecolor{burntorange}{rgb}{.5,.5,.5}
\definecolor{violet}{rgb}{0,0,0}
\def\oran{orange!30}
\tikzstyle{vertex}=[draw,circle,burntorange, text=violet,minimum width=20pt]

\usetikzlibrary{arrows,decorations.markings}



\usepackage{polski}
\usepackage[utf8]{inputenc}
\begin{document}


\title{ Laboratorium Rozpoznawania Obrazów – Ćwiczenie \#3 \& \#4 Rozpoznawanie cyfr pisanych ręcznie }


\author{Michał Sypetkowski}
\maketitle



% TODO ma być w doc:
% jakość każdego z 45 klasyfikatorów
% od 7 jest 9 ekspertów i 36 nieuków

% 2 część do zrobienia jest ciekawsza
% ograniczyć rozległość zespołów jak badamy każda cyfra z każdą

% jak dokonamy podziału na grupy to będzie głosowało 12 klasyfikatorów a nie 45
% w różnych grupach uzyskamy różną jakość (zależy jak dobże się cyferki oddzielają)

% ostatnia rzecz do zrobienia:
% klasyfikator który powie że to jest cyferka z danej grupy (np. A lub B lub C)
% one vs one?

% A 3 5 8
% B 4 7 9
% B 0 1 2 6
% 12 ?

% Podział musi być naprawde dobry żeby wynik był lepszy
% a to dużo trzebaby siedizeć, ale szkoda czasu

% confustion passes - check

\section{Dane i ogólne uwagi}
Eksperymenty przeprowadzane są na zbiorze danych MNIST
\footnote{\url{http://yann.lecun.com/exdb/mnist/}}
Mamy 60k przykładów trenujących i 10k do testowania.

Zbiór trenujący - pliki:
\begin{verbatim}
train-images-idx3-ubyte
train-labels-idx1-ubyte
\end{verbatim}

Zbiór testujący:
\begin{verbatim}
t10k-images-idx3-ubyte
t10k-labels-idx1-ubyte
\end{verbatim}

Skrypt \texttt{genData.m} zmniejsza liczbę wymiarów za pomocą PCA
i zapisuje dane używane później do eksperymentów w plikach:
\begin{verbatim}
train trainl test testl
\end{verbatim}

Eksperymenty opisane w sekcji \ref{canonical} są zaimplementowane w pliku \texttt{main.m},
a te opisane w sekcji \ref{improved} -- w pliku \texttt{main2.m}.

\section{Rozwiązanie "kanoniczne"}
\label{canonical}

W rozwiązaniu kanonicznym trenowane jest 45 klasyfikatorów liniowych
i przeprowadzane jest głosowanie typu OVO.
Trenowanie pojedyńczego klasyfikatora jest zaimplementowane w pliku \texttt{perceptron.m}.
Każdy klasyfikator (spośród 45) był trenowany po 10 razy aby wybrać ten najlepszy.

\subsection{Testy algorytmu dla wielowymiarowych danych.}
\label{multidim}
Wyniki klasyfikatora w zależności od liczby atrybutów (redukcja PCA) przedstawione są w tebeli \ref{table:attrCount},
a wyniki na zbiorze trenującym w tabeli \ref{table:attrCountTrain}.

W razie potrzeby wyciągnięcia bardziej szczegółowych danych,
eksperymenty można powtórzyć (ustawione zostało stałe ziarno losowe).

\begin{table}[H]
    \caption{Wyniki klasyfikatora "kanonicznego" dla różnej ilości atrybutów - na zbiorze testowym
    \label{table:attrCount}
    }
\begin{center}
    \begin{tabular}{| l | l | l | l |}
    \hline
        Ilość atrybutów & precyzja & błąd & wsp. odrzuconych \\
    \hline
        2  & 0.374 & 0.447 & 0.179 \\
        10 & 0.797 & 0.151 & 0.052 \\
        20 & 0.893 & 0.073 & 0.033 \\
        40 & 0.914 & 0.056 & 0.030 \\
        80 & 0.923 & 0.048 & 0.029 \\
        160& 0.924 & 0.049 & 0.028 \\
        784& 0.919 & 0.046 & 0.035 \\
        784 - bez PCA & 0.925 & 0.051 & 0.025 \\
    \hline
    \end{tabular}
\end{center}
\end{table}

\begin{table}[H]
    \caption{Wyniki klasyfikatora "kanonicznego" dla różnej ilości atrybutów - na zbiorze trenującym
    \label{table:attrCountTrain}
    }
\begin{center}
    \begin{tabular}{| l | l | l | l |}
    \hline
        Ilość atrybutów & precyzja & błąd & wsp. odrzuconych \\
    \hline
        2  & 0.372 & 0.451 & 0.176 \\
        10 & 0.793 & 0.152 & 0.055 \\
        20 & 0.888 & 0.079 & 0.033 \\
        40 & 0.912 & 0.057 & 0.030 \\
        80 & 0.925 & 0.048 & 0.027 \\
        160& 0.930 & 0.044 & 0.026 \\
        784& 0.935 & 0.038 & 0.028 \\
        784 - bez PCA & 0.928 & 0.046 & 0.027 \\
    \hline
    \end{tabular}
\end{center}
\end{table}

Wynik dla 160 wymiarowych danych niewiele różni się od tego dla 80 wymiarowych.
Jako rozwiązanie "kanoniczne" będzie przyjmowany klasyfikator działający na 80 atrybutach.

\subsection{Szczegółowe wyniki dla klasyfikatora działającego na 80 atrybutach}

W tej sekcji przedstawione są tylko wyniki na zbiorze testującym
(wyniki na zbiorze trenującym nie zaskakiwały w sekcji \ref{multidim}, to najprawdopodobniej i tutaj tak będzie).

Ktyterium odrzucania polega na odrzuceniu w przypadku nie osiągnięcia maksymalnej ilości głosów za którąś z klas.
Rezultat pokazuje \ref{table:noReject}.
Drugi wiersz tabeli to wyniki eksperymentu, gdzie brana jest pierwsza z brzegu klasa z maksymalną ilością głosów.
Przykłady odrzucone w 1/3 są klasyfikowane poprawnie -- lepiej niż losowo (1/10).

% kryterium to mozna uznać za słuszne --

Macierz pomyłek dla tego klasyfikatora jest przedstawiona w tabeli \ref{table:confusion},
a wyniki skuteczności separacji dla poszczególnych 45 klasyfikatorów w tabeli \ref{table:indiv}.
Najwięcej jest pomyłek takich, że klasyfikator uznaje cyfry cyfrę 3 za 5 lub 8.
Cyfra 8 jest mylona z różnymi cyframi: 1, 2, 3 oraz 5.
Ogólnie, obserwacje można podsumować tabelą \ref{table:confObservation}.


\begin{table}[H]
    \caption{Wyniki wybranego klasyfikatora "kanonicznego" - wpływ dopuszczenia odrzucania decyzji
    \label{table:noReject}
    }
\begin{center}
    \begin{tabular}{| l | l | l | l |}
    \hline
        & precyzja & błąd & wsp. odrzuconych \\
    \hline
        z odrzuceniem  & 0.925 & 0.048 & 0.027 \\
        bez odrzucenia & 0.934 & 0.066 &  0.000 \\

    \hline
    \end{tabular}
\end{center}
\end{table}


\begin{table}[H]
    \caption{Macierz pomyłek dla klasyfikatora "kanonicznego".
    Wiersze odpowiadają odpowiedziom klasyfikatora (a kolumny -- "ground truth").
    \label{table:confusion}
    }
\begin{center}
    \begin{tabular}{| l | l | l | l | l | l | l | l | l | l | l | l | l |}
    \hline
        - & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & reject\\
    \hline
        0 & 950 &     0&      0&      1&      0&      5&      5&      0&      0&      1&     18 \\
        1 & 0   &  1096&      5&      1&      0&      1&      2&      1&     16&      0&     13 \\
        2 & 1   &     2&    958&      6&      5&      1&      6&      5&     19&      0&     29 \\
        3 & 0   &     1&      5&    928&      1&     18&      1&      8&     10&      4&     34 \\
        4 & 1   &     0&      5&      1&    915&      0&      6&      2&      5&     20&     27 \\
        5 & 7   &     1&      0&     36&      3&    781&      9&      1&     17&      3&     34 \\
        6 & 5   &     2&      9&      1&      2&     18&    899&      1&      1&      0&     20 \\
        7 & 0   &     3&     19&      6&      2&      0&      0&    940&      1&     21&     36 \\
        8 & 3   &     0&      3&     27&      3&     20&      3&      3&    862&      4&     46 \\
        9 & 3   &     5&      1&      6&     31&      4&      0&     21&      5&    903&     30 \\

    \hline
    \end{tabular}
\end{center}
\end{table}

\begin{table}[H]
    \caption{ Najczęściej mylone cyfry
    \label{table:confObservation}
    }
\begin{center}
    \begin{tabular}{| l | l | l | l | l | l | l | l | l | l | l | l | l | l | l |}
    \hline
        cyfry mylone z 0 & z 1 & z 2 & z 3 & z 4 & z 5 & z 6 & z 7 & z 8 & z 9 \\
    \hline
        -     &% 0 
        -     &% 1 
        7     &% 2 
        5,8   &% 3
        9     &% 4 
        3,6,8 &% 5 
        -     &% 6 
        9     &% 7 
        1,2,3,5  &% 8 
        4,7   \\% 9 
    \hline
    \end{tabular}
\end{center}
\end{table}


\begin{table}[H]
    \caption{Wyniki pojedyńczych klasyfikatorów
    \label{table:indiv}
    }
\begin{center}
    \begin{tabular}{| l | l | l | l | l | l | l | l | l | l | l | l | l |}
    \hline
        - & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 \\
    \hline
 0 &  -     & 0.999 & 0.991 & 0.993 & 0.997 & 0.990 & 0.990 & 0.995 & 0.993 & 0.994 \\
 1 &  -     & -     & 0.993 & 0.995 & 1.000 & 0.993 & 0.995 & 0.992 & 0.985 & 0.995 \\
 2 &  -     & -     & -     & 0.977 & 0.982 & 0.979 & 0.983 & 0.978 & 0.978 & 0.981 \\
 3 &  -     & -     & -     & -     & 0.995 & 0.958 & 0.992 & 0.980 & 0.961 & 0.981 \\
 4 &  -     & -     & -     & -     & -     & 0.988 & 0.989 & 0.989 & 0.991 & 0.965 \\
 5 &  -     & -     & -     & -     & -     & -     & 0.972 & 0.993 & 0.956 & 0.985 \\
 6 &  -     & -     & -     & -     & -     & -     & -     & 0.993 & 0.990 & 0.995 \\
 7 &  -     & -     & -     & -     & -     & -     & -     & -     & 0.991 & 0.953 \\
 8 &  -     & -     & -     & -     & -     & -     & -     & -     & -     & 0.981 \\
 9 &  -     & -     & -     & -     & -     & -     & -     & -     & -     & -     \\
    \hline
    \end{tabular}
\end{center}
\end{table}


\section{Próba ulepszenia rozwiązania "kanonicznego"}
\label{improved}
% pomysł: subuj prawdopodobieńśtwa w głosowaniu a nie decyzje

Eksperyment polega na dodaniu dodatkowego poziomu klasyfikacji.
Najpierw przeprowadzana jest klasyfikacja na predefiniowane grupy cyfr,
a następnie klasyfikacja OVO wewnątrz tych grup
(przy użyciu części klasyfikatorów elementarnych z rozwiązania "kanonicznego").

Do wstępniej klasyfikacji wykożystano równierz podejście z klasyfikacją OVO.
Wstępne klasyfikatory zostały wytrenowane na całym zbiorze trenującym
z odpowiednio zmapowanymi etykietami.
Na podstawie tabeli \ref{table:confObservation} można narysować graf \ref{fig:graph}.
Na jego podstawie próbujemy wyznaczyć odpowiednie grupowanie.
Tabela \ref{table:grouping} przedstawia wyniki dla kilku grupowań inspirowanych otrzymanym grafem.

Niestety tym sposobem nie udało się uzyskać lepszej precyzji całościowej klasyfikacji.
Tabela \ref{table:grouping} nasuwa wręcz hipotezę, że nim bardziej grupowanie jest zbliżone do trywialnego (jedna grupa lub 10 grup)
tym wynik jest lepszy. Dodatkowo, mozna zauważyć że nim grupowanie jest bardziej trywialne tym mniej jest elementarnych klasyfikatorów
(sumarycznie w grupowaniu i wewnątrz grup). Dla przykładu grupowanie \verb|{[0;1;2;6];[3;5;8];[4;7;9]}| ma tylko 3 klasyfikatory do grupowania
i w sumie 12 wewnątrz grup -- moznaby w jakimś zastosowaniu rozpatrzyć użycie takiego klasyfikatora ze względów wydajnościowych.
Dla kompletności wyników, macierz pomyłek klasyfikatora grupującego dla tego grupowania podana jest w tabeli \ref{table:groupConf}.

\begin{figure}[H]
    \caption{Graf najczęstszych pomyłek
    \label{fig:graph}
    }
\begin{center}

\begin{tikzpicture}[spring layout, node distance=60pt]
\node (0) [vertex] {0};
\node (1) [vertex] {1};
\node (2) [vertex] {2};
\node (3) [vertex] {3};
\node (4) [vertex] {4};
\node (5) [vertex] {5};
\node (6) [vertex] {6};
\node (7) [vertex] {7};
\node (8) [vertex] {8};
\node (9) [vertex] {9};
\path (2) edge[->] (7); 
\path (3) edge[->] (5); 
\path (3) edge[->] (8); 
\path (4) edge[->] (9); 
\path (5) edge[->] (3); 
\path (5) edge[->] (6); 
\path (5) edge[->] (8); 
\path (7) edge[->] (9); 
\path (8) edge[->] (1); 
\path (8) edge[->] (2); 
\path (8) edge[->] (3); 
\path (8) edge[->] (5); 
\path (9) edge[->] (4); 
\path (9) edge[->] (7); 
\end{tikzpicture}

\end{center}
\end{figure}

\begin{table}[H]
    \caption{Wyniki dla różnych grupowań
    \label{table:grouping}
    }
\begin{center}
    \begin{tabular}{| l | p{45mm} | l | l | l | l | l | l | l | l | l | l | l |}
    \hline
        grupowanie & komentarz & precyzja & błąd & wsp. odrz. \\
    \hline
        \verb|[0;1;2;3;4;5;6;7;8;9]| & brak grupowania \newline (zwykłe OVO) &0.9232  &  0.0481   & 0.0287 \\
    \hline
        \verb|[0];[1];[6];[2;3;4;5;7;8;9]| & odcięcie odstających \newline (łatwo separowalnych) cyfr & 0.9154   &0.0638 &  0.0208 \\

    \hline
        \verb|[0];[1];[2];[6];[3;4;5;7;8;9]| & odcięcie odstających \newline (łatwo separowalnych) cyfr \newline oraz cyfry 2& 0.9162 &  0.0664 &  0.0174 \\
    \hline
        \verb|[0];[1];[2];[6];[3;5;8];[4;7;9]| & silne spójne składowe grafu & 0.9192  & 0.0639 &  0.0169 \\
    \hline
        \verb|[0];[1;2;3;4;5;6;7;8;9]| & słabe spójne składowe grafu & 0.9194 &  0.0553 &  0.0253 \\
    \hline
        \verb|[0;1;2;6];[3;5;8];[4;7;9]| & silne spójne składowe grafu (jednoelementowe składowe w jednej grupie) & 0.8961 &  0.0903 &  0.0136 \\
    \hline

    \end{tabular}
\end{center}
\end{table}


\begin{table}[H]
    \caption{Macierz pomyłek podziału na grupy dla groupowania dla podziału na 3 grupy (ostatni wiersz tabeli \ref{table:grouping})
    \label{table:groupConf}
    }
\begin{center}
    \begin{tabular}{| l | l | l | l | l | l | l | l | l | l | l | l | l |}
    \hline
        - & 1 & 2 & 3 & reject \\
    \hline
        1  &  3844 &   211&     39  &   11 \\
        2  &  185  & 2620 &    52   &  19 \\
        3  &  69   &  56  & 2866    & 28 \\
    \hline
    \end{tabular}
\end{center}
\end{table}




\end{document}
